{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from braindecode.datasets.mne import (create_from_mne_epochs)\n",
    "import mne\n",
    "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
    "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
    "import numpy as np\n",
    "from braindecode.datautil.windowers import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "config = {\"folder_path\": (\"/storage/store/data/camcan/camcan47/cc700/\"\n",
    "                     \"meg/pipeline/release004/data/aamod_meg_get_fif_00001/\"),\n",
    "          \"list_indiv\": ['CC110033', 'CC110037', 'CC110045'],\n",
    "          \"maxfilter_calibration_file_path\": \"sss_cal.dat\",\n",
    "          \"empty_room_path\": (\"/storage/store/data/camcan/camcan47/cc700/meg/\"\n",
    "                              \"pipeline/release004/emptyroom/\"),\n",
    "          \"event_id\": {\"Auditory 300Hz\": 6, \n",
    "                       \"Auditory 600Hz\": 7,\n",
    "                       \"Auditory 1200Hz\": 8, \n",
    "                       \"Visual Checkerboard\": 9},\n",
    "          \"tmin\": -0.2, \n",
    "          \"tmax\": 0.5,\n",
    "          \"factor_new\": 1e-3,\n",
    "          \"init_block_size\": 1000,\n",
    "         \n",
    "          \"trial_start_offset_seconds\": -0.5}\n",
    "\n",
    "class DataImporter:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.final_epochs_list = []\n",
    "        self.dataset = []\n",
    "        \n",
    "    def _import_epochs_list(self):\n",
    "        for indiv in config[\"list_indiv\"]:\n",
    "            raw_path = data_path + indiv + \"/passive/passive_raw.fif\"\n",
    "            empty_raw_path = data_path + indiv + \"/emptyroom_\" + indiv + \".fif\"\n",
    "            config[\"raw_path\"] = raw_path\n",
    "            config[\"empty_raw_path\"] = empty_raw_path\n",
    "            new_ep_gen = EpochGenerator(self, config)\n",
    "            new_ep_gen.compute_epochs()\n",
    "            self.final_epochs_list.append(new_ep_gen.return_epochs())\n",
    "            \n",
    "    def _create_braindecode_dataset(self):\n",
    "        subject_id = 22\n",
    "        event_codes = [5, 6, 9, 10, 13, 14]\n",
    "        self.windows_datasets = create_from_mne_epochs(list_of_epochs,\n",
    "                                                  window_size_samples=50,\n",
    "                                                  window_stride_samples=50,\n",
    "                                                  drop_last_window=False)\n",
    "        \n",
    "    def compute(self):\n",
    "        self._import_epoch_list()\n",
    "        self._create_braindecode_dataset()\n",
    "    \n",
    "    def get(self):\n",
    "        return(self.windows_datasets)\n",
    "        \n",
    "        \n",
    "class BrainDecodeModel:\n",
    "    \n",
    "    def __init__(self, windows_datasets):\n",
    "        self.preprocessors = None\n",
    "        self.windows_datasets = None\n",
    "        \n",
    "    def _preprocess_data():\n",
    "        self.preprocessors = [\n",
    "            # keep only EEG sensors\n",
    "            MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "            # convert from volt to microvolt, directly modifying the numpy array\n",
    "            NumpyPreproc(fn=lambda x: x * 1e6)\n",
    "            # exponential moving standardization\n",
    "            NumpyPreproc(fn=exponential_moving_standardize, factor_new=factor_new,\n",
    "                init_block_size=init_block_size)\n",
    "        ]\n",
    "        preprocess(dataset, preprocessors)\n",
    "\n",
    "    def _train_test_split():\n",
    "        self.splitted = self.windows_dataset.split('session')\n",
    "        self.train_set = self.splitted['session_T']\n",
    "        self.valid_set = self.splitted['session_E']\n",
    "\n",
    "\n",
    "    def _check_if_gpu_available():\n",
    "        self.cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "        self.device = 'cuda' if cuda else 'cpu'\n",
    "        if cuda:\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            \n",
    "    def _define_model():\n",
    "    \n",
    "        n_classes=4\n",
    "        # Extract number of chans and time steps from dataset\n",
    "        n_chans = train_set[0][0].shape[0]\n",
    "        input_window_samples = train_set[0][0].shape[1]\n",
    "        model = ShallowFBCSPNet(\n",
    "            n_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length='auto')\n",
    "\n",
    "        # Send model to GPU\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "            \n",
    "        lr = 0.0625 * 0.01\n",
    "        weight_decay = 0\n",
    "\n",
    "        # For deep4 they should be:\n",
    "        # lr = 1 * 0.01\n",
    "        # weight_decay = 0.5 * 0.001\n",
    "        batch_size = 64\n",
    "        n_epochs = 4\n",
    "\n",
    "        clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.NLLLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "            optimizer__lr=lr,\n",
    "            optimizer__weight_decay=weight_decay,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[\n",
    "                \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "            ],\n",
    "            device=device,\n",
    "        )\n",
    "    \n",
    "    def _train_model():\n",
    "    \n",
    "        # These values we found good for shallow network:\n",
    "        \n",
    "        # Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "        # in the dataset.\n",
    "        clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "\n",
    "    def _get_results():\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract loss and accuracy values for plotting from history object\n",
    "results_columns = ['train_loss', 'valid_loss', 'train_accuracy', 'valid_accuracy']\n",
    "df = pd.DataFrame(clf.history[:, results_columns], columns=results_columns,\n",
    "                  index=clf.history[:, 'epoch'])\n",
    "\n",
    "# get percent of misclass for better visual comparison to loss\n",
    "df = df.assign(train_misclass=100 - 100 * df.train_accuracy,\n",
    "               valid_misclass=100 - 100 * df.valid_accuracy)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "fig, ax1 = plt.subplots(figsize=(8, 3))\n",
    "df.loc[:, ['train_loss', 'valid_loss']].plot(\n",
    "    ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False, fontsize=14)\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
    "ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "df.loc[:, ['train_misclass', 'valid_misclass']].plot(\n",
    "    ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n",
    "ax2.set_ylabel(\"Misclassification Rate [%]\", color='tab:red', fontsize=14)\n",
    "ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=14)\n",
    "\n",
    "# where some data has already been plotted to ax\n",
    "handles = []\n",
    "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n",
    "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n",
    "plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-da5c6233beb1>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-da5c6233beb1>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    self.empty_room_raw_file_path =\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class EpochGenerator:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.empty_raw_path = config[\"empty_raw_path\"]\n",
    "        self.raw_path = config[\"raw_path\"]\n",
    "        self.raw = None\n",
    "        self.empty_raw = None\n",
    "        self.maxfilter_raw = None\n",
    "        self.maxfilter_empty_raw = None\n",
    "        self.events = None\n",
    "        self.final_epochs = None\n",
    "        self.ica = None\n",
    "        self.reject = None\n",
    "        \n",
    "    def _import_data(self):\n",
    "        self.raw = mne.io.read_raw_fif(self.raw_path)\n",
    "        self.empty_raw = mne.io.read_raw_fif(self.empty_raw_path)\n",
    "        \n",
    "    def _filter_data(self)\n",
    "        self.raw.fix_mag_coil_types()\n",
    "        self.maxfilter_raw = mne.preprocessing.maxwell_filter(self.raw, calibration=self.cal_file_path)\n",
    "        self.maxfilter_raw.filter(l_freq=0.5, h_freq=40)\n",
    "        self.empty_raw.fix_mag_coil_types()\n",
    "        self.maxfilter_empty_raw = mne.preprocessing.maxwell_filter(raw, calibration=\"sss_cal.dat\", coord_frame=\"meg\")\n",
    "        self.maxfilter_empty_raw.filter(l_freq=0.5, h_freq=40)\n",
    "\n",
    "    def _build_epochs_evoked(self):\n",
    "        self.events = mne.find_events(self.raw, stim_channel='STI101')\n",
    "        self.raw.info['projs'] = list()  # remove proj, don't proj while interpolating\n",
    "        self.epochs = mne.Epochs(self.raw, self.events, config[\"event_id\"], config[\"tmin\"], config[\"tmax\"],\n",
    "                            baseline=(None, 0), reject=None,\n",
    "                            verbose=False, detrend=0, preload=True)\n",
    "        self.reject = get_rejection_threshold(epochs)\n",
    "\n",
    "    def _create_epochs(raw):\n",
    "        self.ica = mne.preprocessing.ICA(n_components=30)\n",
    "        self.ica.fit(raw)\n",
    "        # raw.load_data()\n",
    "        self.ica.exclude = []\n",
    "        eog_indices, eog_scores = self.ica.find_bads_eog(self.raw)\n",
    "        ecg_indices, ecg_scores = self.ica.find_bads_ecg(self.raw, method='correlation')\n",
    "        self.ica.exclude = ecg_indices + eog_indices\n",
    "        self.epochs = mne.Epochs(self.raw, events, event_id, tmin, tmax,\n",
    "                                 baseline=(None, 0), reject=reject,\n",
    "                                 verbose=False, detrend=0, preload=True)\n",
    "    \n",
    "    def compute(self):\n",
    "        self._import_data()\n",
    "        self._filter_data()\n",
    "        self._build_epochs_evoked()\n",
    "        self._create_epochs()\n",
    "        \n",
    "    def get(self):\n",
    "        return(self.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-a577a0dcc470>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-a577a0dcc470>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class EpochObject:\n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    data_path = ()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "from autoreject import get_rejection_threshold\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import index_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_epochs_evoked(raw):\n",
    "\n",
    "    event_id = {\"Auditory 300Hz\": 6, \"Auditory 600Hz\": 7,\n",
    "                \"Auditory 1200Hz\": 8, \"Visual Checkerboard\": 9}\n",
    "    events = mne.find_events(raw, stim_channel='STI101')\n",
    "    raw.info['projs'] = list()  # remove proj, don't proj while interpolating\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n",
    "                        baseline=(None, 0), reject=None,\n",
    "                        verbose=False, detrend=0, preload=True)\n",
    "    reject = get_rejection_threshold(epochs)\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n",
    "                        baseline=(None, 0), reject=reject,\n",
    "                        verbose=False, detrend=0, preload=True)\n",
    "    evoked = epochs[\"Auditory 300Hz\"].average()\n",
    "    print(\"Evoked for Auditory 300Hz : \\n\")\n",
    "    evoked.plot()\n",
    "    plt.show()\n",
    "\n",
    "    evoked = epochs[\"Auditory 600Hz\"].average()\n",
    "    print(\"Evoked for Auditory 600Hz : \\n\")\n",
    "    evoked.plot()\n",
    "    plt.show()\n",
    "\n",
    "    evoked = epochs[\"Auditory 1200Hz\"].average()\n",
    "    print(\"Evoked for Auditory 1200Hz : \\n\")\n",
    "    evoked.plot()\n",
    "    plt.show()\n",
    "\n",
    "    evoked = epochs[\"Visual Checkerboard\"].average()\n",
    "    print(\"Evoked for Visual Checkerboard : \\n\")\n",
    "    evoked.plot()\n",
    "    plt.show()\n",
    "\n",
    "    evoked = epochs.average()\n",
    "\n",
    "    return (epochs, evoked)\n",
    "\n",
    "\n",
    "def plot_sti_cols(raw):\n",
    "    sti_cols = [i for i in range(len(raw.ch_names))\n",
    "                if \"STI\" in raw.ch_names[i]]\n",
    "    for i in sti_cols:\n",
    "        print(\"Channel {} :\".format(raw.ch_names[i]))\n",
    "        plt.figure(figsize=(15, 2))\n",
    "        plt.plot(list(range(len(raw._data[i]))), raw._data[i])\n",
    "        x1, x2, y1, y2 = plt.axis()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def compare_noise_cov(epochs, empty_raw):\n",
    "    noise_cov_baseline = mne.compute_covariance(epochs, tmax=0)\n",
    "    noise_cov = mne.compute_raw_covariance(empty_raw, tmin=0, tmax=None)\n",
    "    noise_cov_reg = mne.compute_covariance(\n",
    "        epochs, tmax=0., method='auto', rank=None)\n",
    "    noise_cov.plot(empty_raw.info, proj=True)\n",
    "    noise_cov_reg.plot(empty_raw.info, proj=True)\n",
    "    noise_cov_baseline.plot(epochs.info, proj=True)\n",
    "    print(\"Gotcha !\")\n",
    "    evoked = epochs.average()\n",
    "    evoked.plot_white(noise_cov_reg, time_unit='s')\n",
    "\n",
    "\n",
    "def build_dspm(raw):\n",
    "\n",
    "    # Set dir\n",
    "    data_path = \"/storage/store/data/camcan-mne/freesurfer/\"\n",
    "    subjects_dir = data_path\n",
    "    subject = \"CC110033\"\n",
    "    bem_dir = op.join(subjects_dir, subject, 'bem')\n",
    "    fname_aseg = op.join(subjects_dir, subject, 'mri', 'aseg.mgz')\n",
    "    fname_model = op.join(bem_dir, 'CC110033-meg-bem.fif')\n",
    "\n",
    "    # List substructures we are interested in. We select only the\n",
    "    # sub structures we want to include in the source space\n",
    "    labels_vol = ['Left-Amygdala',\n",
    "                'Left-Thalamus-Proper',\n",
    "                'Left-Cerebellum-Cortex',\n",
    "                'Brain-Stem',\n",
    "                'Right-Amygdala',\n",
    "                'Right-Thalamus-Proper',\n",
    "                'Right-Cerebellum-Cortex']\n",
    "\n",
    "    # Get a surface-based source space, here with few source points for speed\n",
    "    # in this demonstration, in general you should use oct6 spacing!\n",
    "    src = mne.setup_source_space(subject, spacing='oct5',\n",
    "                                add_dist=False, subjects_dir=subjects_dir)\n",
    "\n",
    "    # Now we create a mixed src space by adding the volume regions specified in the\n",
    "    # list labels_vol. First, read the aseg file and the source space bounds\n",
    "    # using the inner skull surface (here using 10mm spacing to save time,\n",
    "    # we recommend something smaller like 5.0 in actual analyses):\n",
    "\n",
    "    vol_src = mne.setup_volume_source_space(\n",
    "        subject, mri=fname_aseg, pos=5, bem=fname_model,\n",
    "        volume_label=labels_vol, subjects_dir=subjects_dir,\n",
    "        add_interpolator=True,  # just for speed, usually this should be True\n",
    "        verbose=True)\n",
    "\n",
    "    # Generate the mixed source space\n",
    "    # src += vol_src\n",
    "\n",
    "    # Visualize the source space.\n",
    "    # src.plot(subjects_dir=subjects_dir)\n",
    "\n",
    "    # n = sum(src[i]['nuse'] for i in range(len(src)))\n",
    "    # print('the src space contains %d spaces and %d points' % (len(src), n))\n",
    "\n",
    "    event_id = {\"Auditory 300Hz\": 6, \"Auditory 600Hz\": 7,\n",
    "                \"Auditory 1200Hz\": 8, \"Visual Checkerboard\": 9}\n",
    "    events = mne.find_events(raw, stim_channel='STI101')\n",
    "    raw.info['projs'] = list()  # remove proj, don't proj while interpolating\n",
    "    tmin, tmax = -0.2, 0.5\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n",
    "                        baseline=(None, 0), reject=None,\n",
    "                        verbose=False, detrend=0, preload=True)\n",
    "    reject = get_rejection_threshold(epochs)\n",
    "    ica = mne.preprocessing.ICA(n_components=0.95, random_state=0).fit(raw, decim=1, reject=reject)\n",
    "    eog_epochs = mne.preprocessing.create_eog_epochs(raw, reject=None)\n",
    "    eog_inds, eog_scores = ica.find_bads_eog(eog_epochs)\n",
    "    ica.plot_scores(eog_scores, eog_inds)  # see scores the selection is based on\n",
    "    # ica.plot_components(eog_inds)  # view topographic sensitivity of components\n",
    "    ica.plot_overlay(eog_epochs.average())  # inspect artifact removal\n",
    "    ica.apply(epochs)  # clean data, default in place\n",
    "    evoked = [epochs[k].average() for k in event_id]\n",
    "    for e in evoked:\n",
    "        e.plot(ylim=dict(mag=[-400, 400]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # estimate noise covarariance\n",
    "    noise_cov = mne.compute_covariance(epochs, tmax=0, method='shrunk',\n",
    "                                    rank=None)\n",
    "    contrast = mne.combine_evoked(evoked, weights=\"equal\") \n",
    "    # The transformation here was aligned using the dig-montage. It's included in\n",
    "    # the spm_faces dataset and is named SPM_dig_montage.fif.\n",
    "    trans_fname = '/storage/store/data/camcan-mne/trans/sub-CC110033-trans.fif'\n",
    "    evoked[0].plot_white(noise_cov)\n",
    "    # maps = mne.make_field_map(evoked[0], trans_fname, subject='spm',\n",
    "    #                           subjects_dir='/storage/store/data/camcan-mne/trans/', n_jobs=1)\n",
    "\n",
    "    # evoked[0].plot_field(maps, time=0.170)\n",
    "    src = mne.setup_source_space(\"CC110033\", spacing='oct5',\n",
    "                                 add_dist=False, subjects_dir=\"/storage/store/data/camcan-mne/freesurfer/\")\n",
    "    bem = \"/storage/store/data/camcan-mne/freesurfer/CC110033/bem/CC110033-meg-bem.fif\"\n",
    "    forward = mne.make_forward_solution(contrast.info, trans_fname, src, bem)\n",
    "    snr = 3.0\n",
    "    lambda2 = 1.0 / snr ** 2\n",
    "    method = 'dSPM'\n",
    "\n",
    "    inverse_operator = mne.minimum_norm.make_inverse_operator(contrast.info, forward, noise_cov,\n",
    "                                            loose=0.2, depth=0.8)\n",
    "\n",
    "    # Compute inverse solution on contrast\n",
    "\n",
    "    stc = mne.minimum_norm.apply_inverse(contrast, inverse_operator, lambda2, method, pick_ori=None)\n",
    "    # stc.save('spm_%s_dSPM_inverse' % contrast.comment)\n",
    "\n",
    "    # Plot contrast in 3D with PySurfer if available\n",
    "    subjects_dir = \"/storage/store/data/camcan-mne/freesurfer/\"\n",
    "    # brain = stc.plot(hemi='both', subjects_dir=subjects_dir, initial_time=0.170,\n",
    "    #                  views=['ven'], clim={'kind': 'value', 'lims': [3., 6., 9.]})\n",
    "    stc.crop(0.0, 0.2)\n",
    "\n",
    "    # Export result as a 4D nifti object\n",
    "    img = stc.as_volume(inverse_operator[\"src\"], mri_resolution=False)  # set True for full MRI resolution\n",
    "\n",
    "    # Save it as a nifti file\n",
    "    # nib.save(img, 'mne_%s_inverse.nii.gz' % method)\n",
    "\n",
    "    t1_fname = \"/storage/store/data/camcan-mne/freesurfer/CC110033/mri/T1.mgz\"\n",
    "\n",
    "    # Plotting with nilearn ######################################################\n",
    "    plot_stat_map(index_img(img, 61), t1_fname, threshold=8., title='%s (t=%.1f s.)' % (method, stc.times[61]))\n",
    "\n",
    "\n",
    "def ICA_preprocessing(raw):\n",
    "    ica = mne.preprocessing.ICA(n_components=15, random_state=97)\n",
    "    ica.fit(raw)\n",
    "    raw.load_data()\n",
    "    ica.plot_sources(raw)\n",
    "    ica.plot_components()\n",
    "    ica.exclude = []\n",
    "    # find which ICs match the EOG pattern\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw)\n",
    "    ica.exclude = eog_indices\n",
    "\n",
    "    # barplot of ICA component \"EOG match\" scores\n",
    "    ica.plot_scores(eog_scores)\n",
    "\n",
    "    # plot diagnostics\n",
    "    ica.plot_properties(raw, picks=eog_indices)\n",
    "\n",
    "    # plot ICs applied to raw data, with EOG matches highlighted\n",
    "    ica.plot_sources(raw)\n",
    "    eog_epochs = mne.preprocessing.create_eog_epochs(raw, reject=None)\n",
    "    eog_evoked = eog_epochs.average()\n",
    "    # plot ICs applied to the averaged EOG epochs, with EOG matches highlighted\n",
    "    ica.plot_sources(eog_evoked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
